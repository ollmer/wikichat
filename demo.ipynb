{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec79d766-939a-451a-bb6c-7e1478df6e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/conda/envs/wikichat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "from augmented_llm import AugmentedLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be90ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ./models/Wizard-Vicuna-13B-Uncensored.ggmlv3.q4_K_M.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 15 (mostly Q4_K - Medium)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: using CUDA for GPU acceleration\n",
      "llama_model_load_internal: mem required  = 2135.98 MB (+ 1608.00 MB per state)\n",
      "llama_model_load_internal: allocating batch_size x 1 MB = 512 MB VRAM for the scratch buffer\n",
      "llama_model_load_internal: offloading 40 repeating layers to GPU\n",
      "llama_model_load_internal: offloading non-repeating layers to GPU\n",
      "llama_model_load_internal: offloading v cache to GPU\n",
      "llama_model_load_internal: offloading k cache to GPU\n",
      "llama_model_load_internal: offloaded 43/43 layers to GPU\n",
      "llama_model_load_internal: total VRAM used: 9493 MB\n",
      "....................................................................................................\n",
      "llama_init_from_file: kv self size  = 1600.00 MB\n"
     ]
    }
   ],
   "source": [
    "llm = AugmentedLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bb1548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President of the United States is currently Joe Biden who was elected as the 46th president of the country on January 20, 2021 and assumed office on that day. He won against his Republican rival, Donald Trump, in the November 2020 general election.\n",
      "\n",
      "Sources:\n",
      "https://en.wikipedia.org/wiki/List%20of%20presidents%20of%20the%20United%20States List of presidents of the United States.\n",
      "The president of the United States is the head of state and head of government of the United States, indirectly elected to a four-year term by the American people through the Electoral College. The officeholder leads the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces. \n",
      "\n",
      "https://en.wikipedia.org/wiki/President%20of%20the%20United%20States%20%28disambiguation%29 President of the United States (disambiguation).\n",
      "The Presidents of the United States of America may also refer to: \n",
      "\n",
      "https://en.wikipedia.org/wiki/President%20of%20the%20United%20States President of the United States.\n",
      "Joe Biden is the 46th and current president of the United States, having assumed office on January 20, 2021. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is the president of the United States?\"\n",
    "answer, docs = llm.ask(question, force_retrieval=True)\n",
    "print(answer)\n",
    "print(\"\\nSources:\")\n",
    "for d in docs:\n",
    "    print(d[\"page_url\"], d[\"text\"], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
